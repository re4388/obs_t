[[CS61B Data Structures and Algorithms|cs61b_index]]


slide: [cs61b 2019 lec13 asymptotics1 - Google 簡報](https://docs.google.com/presentation/d/16IBfr6JGMStfd2WqVaUIg4cWrGyeb_g3otsWpVqZJYw/edit)

有時候，你光是把一個重要的算法（whatevr, ai, 癌症相關，生物醫學等等）
從 square or tube 降到 linear
量小沒差
量大的話就差超級多，甚至是有生之年到幾秒的差異

一個例子
一個`M*N` -> 變成 M+N 的算法 [[m*n_to_m+n, n+1 db query issue]] 
依照下圖，量大(一百萬)的話，差異是 1,036,800 ~ 一百萬倍
![[IMG-cs61b 13. Asymptotics I-20241003104933859.png]]


簡化
![[IMG-cs61b 13. Asymptotics I-20241003104948795.png]]


你要算 big O 的第一步
你還是得找出你要找的是那一個 operation 的 bigO
因為如果你挑的是 like `i=0` -> 這個 也只跑一次 XD
![[IMG-cs61b 13. Asymptotics I-20241003105002506.png]]


這邊是計算 == 操作次數
![[IMG-cs61b 13. Asymptotics I-20241003105020346.png]]

![[IMG-cs61b 13. Asymptotics I-20241003105020498.png|557]]



看下圖 == 的操作次數
展開是一個 box, 就是一個 squre, 就是 N^2  (用幾何，圖像的方式去推論，思考)
也不需要去計算
![[IMG-cs61b 13. Asymptotics I-20241003105046261.png|817]]



思考方法？
可以想像， when N -> 無窮大
那一個會主導
![[IMG-cs61b 13. Asymptotics I-20241003105046415.png]]


Big-theta 就是一個表示法
背後有嚴謹的數學定義(see slide)，但實際分析通常不會用到
![[IMG-cs61b 13. Asymptotics I-20241003105112948.png]]

![[IMG-cs61b 13. Asymptotics I-20241003105128264.png]]




![[IMG-cs61b 13. Asymptotics I-20241003105137375.png]]
解釋:

 1 最低，沒啥說的 
N > log N , 也 okay, logN 就是每次減半的速度

 nLogn > N 
 logN也多疊一個增加速度，因此 n 多疊一個 logN 一定比只有 N 慢
 類似 tree, logN搜，但是另外堆一個 lineaer 的維度，就是 N x LogN的速度
 

n^3 vs 2^n
變數 at power 一定最後會增長更快


n! < n^n
n! 就是 n x n-1 x n-2 x n-3...
因此就是 n^n 的 慢速版本，都是同級的






# Analyzing Runtime Example


Let’s find out the big-O runtime of this wonderful sorting algorithm!
- We enter a while loop until the list is sorted, let’s assume that isSorted runs in O(n)
- while 要一直跑一直跑，隨機到剛好全部都 sorted,   才跳的出來 -> 因此這邊需要跑 N! 次 at worse case, 因為有那麼多組合
- 每一次都需要 O(N) 去 check if it is sorted
- 因此是 O(N * N!)


```java

public int[] bogosort(int[] ints) {
   while (!isSorted(ints)) {  
       Collections.shuffle(ints);  
   }
   return ints;
}

```




# Analyzing Runtime Example 2

答案是 O(log(log(n)))


```java

public void doStuff(int n) {
   int i = 2;
   while (i <= n) {
       i = Math.pow(i, 2);
   }
}

```



   while (i <= n) {
       i = Math.pow(i, 2);
   }

上面這段 code
定義了下面這個 math關係
i^2^k <= n, k 是要 loop 幾次才可以從 while 出來
(第一次就是 i = i ^ 2, 第二次就是 i = i ^ 2 ^ 2,........)

解這個 i^2^k <= n

兩邊取 log

k <= log(log n)

因此這就是 run time

n 持續 growth, k 需要跑幾次的關係



==

## Analyzing Running Time of a Recursive Procedure

```java

    public static void andslam(int N) {
        if(N>0){
            for (int i = 0; i < N; i++) {
                System.out.println("qq");
            }

            // Java, this is int, so 1/2 -> 0.5 -> round to 0 in int!
            andslam(N/2);
        }
    }

```


**1. Height of the tree**

* How many times can you divide $n$ by 2 until you get $n = 1$? Let $h$ be the height.

* $\frac{n}{2^h} = 1$  ➞  $n = 2^h$  ➞  $h = \log_2 n$

**2. Branching factor**

* Note each time `andSlam` is called, it makes **1** recursive call on $\frac{n}{2}$. 

* nodes per layer = 1.

**3. Amount of work each node does**

* Linear relative to input size, so $O(n)$. 

---
![[IMG-cs61b 13. Asymptotics I-20241003105145253.png|460]]


**Now running time of entire recursive procedure can be calculated by summing over entire recursive tree.**

Sum over

run time = 加總 (i form 0 to logN)  to   node/layer * work/node  

多少 layer 就是 i = 0 到 logN 層
每一層一個 node
每一個 node 的 work 是 n/2^i


 $= \sum_{layers}^{\log_2 n} (1) \cdot (\frac{n}{2^i})$ 

 $= \sum_{i = 0}^{\log_2 n}  (\frac{n}{2^i}) = n \sum_{i=0}^{\log_2 n} \frac{1}{2^i}$
 
 

這邊 trick 的點是


![[IMG-cs61b 13. Asymptotics I-20241003105145369.png]]這一個 term 加總是 是常數, 2 以內



or 換另一個表示法
![[IMG-cs61b 13. Asymptotics I-20241003105152269.png]]


 Therefore, the running time of this recursive procedure is **O(n)**. 





# 另一題
![[IMG-cs61b 13. Asymptotics I-20241003105157934.png|584]]


best case, random 都走 0.5 > 那邊 回到上一題情境

worse case,

height is logN
每一個 layer, node 的數量:
node/layer = 2^i  for layer i

然後每一個 node 要做的事情:
work / node = n/(2^i)

加總 from so i = o ~ logN

數學看下面
結果是 n log n
![[IMG-cs61b 13. Asymptotics I-20241003105202950.png]]


# 下一題
![[IMG-cs61b 13. Asymptotics I-20241003105209933.png|476]]


加總 from i = 0 ~ N-1
每一層的 work -> 1
每一layer 的 node -> 2^i

![[IMG-cs61b 13. Asymptotics I-20241003105214001.png]]

![[IMG-cs61b 13. Asymptotics I-20241003105217414.png]]


下一題
![[IMG-cs61b 13. Asymptotics I-20241003105221854.png|543]]


每一層都會掃 n, n-1, n-2 次 -> n!
另外 height i = 0 ~ 加到 N

=> sum(i=0~n) * n! -> `n*n!`

why sum(i=0~n) 是 n
因為就是 1+1...加 n 是 -> n 
沒有變數i 在 left term
![[IMG-cs61b 13. Asymptotics I-20241003105225688.png]]


---






![[IMG-cs61b 13. Asymptotics I-20241003105229275.png]]

The answer is **Θ(N<sup>2</sup>)**. Here's why:

**Code Analysis**

The code has two nested loops:

* **Outer loop:** Runs from `i = 1` to `i <= N * N`, but `i` is doubled in each iteration (`i *= 2`). This means the outer loop runs approximately `log₂(N²)` times, which simplifies to `2log₂(N)`.
* **Inner loop:** Runs from `j = 0` to `j < i`. The number of iterations of this loop depends on the current value of `i`.
	* Let's break down the number of times `System.out.println("moo")` is executed:
	* **Iteration 1 (outer loop):**  `i = 1`, inner loop runs 1 time.
	* **Iteration 2 (outer loop):**  `i = 2`, inner loop runs 4 times.
	* **Iteration 3 (outer loop):**  `i = 4`, inner loop runs 16 times.
	* ...
	* **Last Iteration (outer loop):** `i = N`, inner loop runs `N * N` times.


**Big Theta (Θ) Notation**

Since the dominant term in the summation is `N*N`, the runtime of this code is **Θ(N<sup>2</sup>)**.  
Even though the outer loop has a logarithmic growth, the inner loop's dependency on `i` makes the overall complexity quadratic. 



其他練習

![[IMG-cs61b 13. Asymptotics I-20241003105233137.png]]



![[IMG-cs61b 13. Asymptotics I-20241003105233247.png]]